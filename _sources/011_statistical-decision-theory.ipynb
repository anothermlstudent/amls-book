{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5WkcFj8vMfb"
   },
   "source": [
    "Statistical Decision Theory and Statistical Learning Theory are related fields.\n",
    "\n",
    "For instance, both of them provide frameworks to understand regression. Both of them, use Loss, Risk concepts.\n",
    "\n",
    "- **Statisical Decision theory** studies how we can take good based on data.\n",
    "- **Statistical Learning theory** studies how we can learn from data.\n",
    "\n",
    "This two problems overlap. Taking decisions based on data can be defined as finding a function that given data will output the best action and statistical learning theory will cover how to learn functions from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4me4G3qo9RW"
   },
   "source": [
    "## Elements\n",
    "\n",
    "- actions $a \\in A$\n",
    "- state of the world $\\theta \\in \\Theta$\n",
    "- loss function $L(\\theta,a)$ (Wald introduce the loss function instead of the utility function $ U(a(\\theta)) = -L(\\theta,a)$\n",
    "The loss function doesn't consider the outcome $z=a(\\theta)$ explicitly.\n",
    "However, is state independence that generates that the loss ocurring at differentvalues of $\\theta$ can be directly compared.\n",
    "\n",
    "Regret form of the loss function\n",
    "Since it could be that there is no action $a$ for which $L(\\theta,a)=0$, we can define a regret loss function\n",
    "$L(\\theta,a) = L_u(\\theta,a) - \\inf_{a \\in A} L_u(\\theta,a)$.  \n",
    "This way there will be an $a^*$ for which $L_(\\theta,a^*)=0$\n",
    "\n",
    "Now the question is **how we define a good action**.\n",
    "\n",
    "One option is to try to take an action that will reduce worst possible loss. This is the minimax principle\n",
    "\n",
    "$$ a^* = \\arg\\min_{a} \\max_\\theta L(\\theta,a)$$\n",
    "\n",
    "Expected Utility principle\n",
    "Incorporate info on how probable the different states $\\theta$ are\n",
    "\n",
    "$$ a^* = \\arg\\min_{a} \\int_\\Theta L(\\theta,a) \\pi(\\theta) d\\theta$$\n",
    "\n",
    "## Learning from data\n",
    "- experimental outcome $x$\n",
    "- likelihood $f(x|\\theta)$\n",
    "- decision rule $\\delta$ where $\\delta : \\mathcal{X} \\to A$ and $\\delta \\in D$\n",
    "- risk function $R$\n",
    "\n",
    "$$R(\\theta,\\delta) = \\int_{\\mathcal{x}} L(\\theta,\\delta) f(x|\\theta) dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONdp7CArC8o0"
   },
   "source": [
    "## Bayesian Decision Theory\n",
    "\n",
    "**Bayes Estimator** \n",
    "$$ a^* = \\arg\\min_{a} \\int_\\Theta L(\\theta,a) f(\\theta|x\n",
    ") d\\theta$$\n",
    "\n",
    "From {cite}`murphy_machine_2012` P.176\n",
    "\n",
    "## Frequentist Decision Theory\n",
    "\n",
    "\"In practice, the frequentist approach is usually only applied to one-shot statistical decision problems — such as\n",
    "classification, regression and parameter estimation — since its non-constructive nature makes it difcult to apply to\n",
    "sequential decision problems, which adapt to data online.\" From {cite}`murphy_machine_2012` P.194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6kuUTjS1zwa"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPIf3yFWDATh"
   },
   "source": [
    "This notes are based on the book:\n",
    "- [1] [Parmigiani G., Inoue L. (2019). Decision Theory: Principles and Approaches](https://learning.oreilly.com/library/view/decision-theory/9780471496571/xhtml/ch07.xhtml)\n",
    "{cite}`parmigiani_decision_2009`\n",
    "\n",
    "- [2] [Berger J.O. (1989) Statistical Decision Theory. In: Eatwell J., Milgate M., Newman P. (eds) Game Theory. The New Palgrave. Palgrave Macmillan, London.](https://doi.org/10.1007/978-1-349-20181-5_26) \n",
    "{cite}`berger_statistical_1989`\n",
    "\n",
    "- [3] [Betancourt, Michael (2019). Probabilistic Modeling and Statistical Inference. Retrieved from https://github.com/betanalpha/knitr_case_studies/tree/master/modeling_and_inference, commit b474ec1a5a79347f7c9634376c866fe3294d657a](https://betanalpha.github.io/assets/case_studies/modeling_and_inference.html)\n",
    "\n",
    "- [4] Murphy, K. P. (2012). Machine learning: A probabilistic perspective. Cambridge, Mass: MIT Press.\n",
    "{cite}`murphy_machine_2012`\n",
    "\n",
    "- [5] [Quantitative Analysis for Management, 13](https://learning.oreilly.com/library/view/quantitative-analysis-for/9780134543161/xhtml/fileP7001013399000000000000000001633.xhtml)\n",
    "{cite}`render_quantitative_2017`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZPlYGzsJFNH"
   },
   "source": [
    "```{bibliography} ./references.bib\n",
    ":filter: docname in docnames\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_tdtHqN_TQm"
   },
   "source": [
    "## Statistical Decision Theory for Business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIRIARqg_XuF"
   },
   "source": [
    "En Español:\n",
    "\n",
    "http://fad.unsa.edu.pe/bancayseguros/wp-content/uploads/sites/4/2019/03/Estadistica-para-administracion-y-la-economia.-6Ed.-Newbold-2008.pdf\n",
    "\n",
    "[Apuntes de Decisión - Universidad Carlos III de Madrid](http://ocw.uc3m.es/teoria-de-la-senal-y-comunicaciones/teoria-moderna-de-la-deteccion-y-estimacion-2013/apuntes/apuntesb2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMGrepxV_gOM"
   },
   "source": [
    "## La toma de decisiones en condiciones de incertidumbre\n",
    "- Acciones admisibles\n",
    "\n",
    "## Soluciones que no implican la especificación de probabilidades\n",
    "- Criterio maximin\n",
    "- Criterio de la pérdida de oportunidades minimax\n",
    "- Criterio maximax\n",
    "\n",
    "## Valor monetario esperado\n",
    "- Árboles de decisión\n",
    "- Análisis de sensibilidad\n",
    "\n",
    "## Información muestral: análisis y valor bayesianos\n",
    "- Utilización del teorema de Bayes\n",
    "- El valor de la información muestral\n",
    "- El valor de la información muestral visto por medio de árboles de decisión\n",
    "\n",
    "## Introducción del riesgo: análisis de la utilidad\n",
    "- El concepto de utilidad\n",
    "- Criterio de la utilidad esperada para tomar decisiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYD7qEqaFVmH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Statistical Decision Theory & Statistical Learning Theory.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
