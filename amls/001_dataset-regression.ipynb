{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1XGb02yFAfc"
   },
   "source": [
    "# Regression Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7sjD8u1O5ev"
   },
   "source": [
    "En la práctica, nunca vamos a conocer el verdadero proceso que genera los datos (si lo conocieramos, no necesitaríamos utilizar técnicas de machine learning). El valor de simular ese proceso, es que nos va permitir conocer exactamente su distribución y eso nos va ayudar a entender que tan buenas son nuestras estimaciones y mejorar nuestra intuición sobre los distintos conceptos y métodos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0i9s7S9i2BPr"
   },
   "source": [
    "## The (synthetic) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmoWbvN7Vtal"
   },
   "source": [
    "En vez de jugar con datos reales, vamos a crear nuestros datos ya que conocer exactamente como fueron creados nos va ayudar a experimentar con los conceptos que queremos aprender.\n",
    "\n",
    "Una manera de obtener una fuente de datos infinita es creando una \"maquina generadora de datos\". Esa \"máquina\" la podemos especificar describiendo el proceso a través del cual la \"máquina\" va a poder generar datos.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCp1nYX338gP"
   },
   "source": [
    "Una manera posible, podría ser comenzar con una función $f$, donde\n",
    "\n",
    "$$f(x) = (0.45x-2)^3 - 0.55(0.2x-3)^2- 2.5(0.5x - 3)+ 5$$\n",
    "\n",
    "y agregarle ruido $\\epsilon$ para tener entonces una variable aletoria \n",
    "$$ Y = f(x) + \\epsilon.$$\n",
    "\n",
    "Para nuestro ejercicio, tomemos $\\epsilon \\sim N(\\mu=0,\\sigma^2 = 0.5)$.\n",
    "\n",
    "Para hacerlo todavía más entretenido, vamos a hacer que las $x$ de nuestro dataset también tengan una distribución, por ejemplo, $X \\sim U(a=0,b=10) $.\n",
    "\n",
    "Nota: Elegí una $f(x)$ con una forma \"bastante curva\" para que sean más entretenidos nuestros experimentos y nos restringimos a $x \\in [0,10]$ (cómo $\\mathbb{x}$ es un escalar, usamos la notación $x$ en vez de $\\mathbb{x}$) para facilitar la visualización.\n",
    "\n",
    "Con todo esto, nos queda entonces el siguiente proceso de generación de datos: $ Y = f(X) + \\epsilon$ , con $X \\sim U(a=0,b=10) $ y $\\epsilon \\sim N(\\mu=0,\\sigma^2 = 0.5)$.\n",
    "\n",
    "Para \"usar la máquina\" en este caso y generar una muestra $(x_0,y_0)$, empezamos sampleando $x_0$ de la distribución uniforme, después pasamos $x_0$ por $f$ y obtemos $f(x_0)$, sampleamos $\\epsilon_0$ de la normal (con $\\mu=0$ y $\\sigma^2 = 0.5$ ) y finalemente obtenemos $y_0 = f(x_0) + \\epsilon_0$.\n",
    "\n",
    "Este mismo proceso se puede escribir de la siguiente manera:\n",
    "\n",
    "$$ Y|X \\sim \\mathcal{N}(y|\\mu =f(x),{\\sigma}^2 = 0.5)$$  \n",
    "$$ X \\sim \\mathcal{U}(x|a=0,b=10)$$\n",
    "\n",
    "Esto se conoce como un modelos jerarquico ({cite}`casella_statistical_2001`, Pag 162) y es para mí una forma muy simple e intuitiva de describir un proceso de generación de datos.\n",
    "\n",
    "Para \"usar la máquina\" descripta de esta manera y generar una muestra $(x_0,y_0)$, empezamos sampleando $x_0$ de la distribución uniforme. Después, \"pasamos\" $x_0$ por $f$ para obtener $f(x_0)$. Finalmente sampleamos $y_0$ de una normal con $\\mu=f(x_0)$ y $\\sigma^2 = 0.5$. A este proceso de generar muestras se lo conoce como ancestral sampling ({cite}`bishop_pattern_2007`, Pag 365).\n",
    "\n",
    "Noten que las dos descripciones, aunque son ligeramente diferentes, son completamente equivalentes (van a generar datos con exactamente la misma distribución) y me permiten generar tantos pares $(x,y)$ como queramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOKTKXWgAe-C"
   },
   "source": [
    "## Data distribution $Pr(X,Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRXGHsDkGseo"
   },
   "source": [
    "\n",
    "En este caso, podemos escribir $\\text{Pr}(X,Y)$ de manera analítica,\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Pr}(X,Y) &= \\text{Pr}(Y|X) \\, \\text{Pr}(X) && \\text{(aplicando chain rule)} \\\\\n",
    "&= \\mathcal{N}(y|\\mu =f(x),{\\sigma}^2 = 0.5)\\, \\mathcal{U}(x|a=0,b=10) && \\text{(reemplazando por las definiciones)} \\\\\n",
    "&= \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp} \\Big\\{-\\frac{1}{2\\sigma^2}(y-f(x))^2\\Big\\} \\frac{1}{b-a} \\\\\n",
    "&= \\frac{1}{10\\sqrt{\\pi}}\\text{exp} \\Big\\{-(y-f(x))^2\\Big\\} && \\text{(reemplazando los valores de los parámetros)} .\n",
    "\\end{align*}\n",
    "\n",
    "Dónde usamos que $\\mathcal{N}(y | \\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp} \\Big\\{-\\frac{1}{2\\sigma^2}(y-\\mu)^2\\Big\\}$ y $\\mathcal{U}(x|a,b) = \\frac{1}{b-a}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "y_cOGMcAMiWh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNvnMTe15gUi"
   },
   "source": [
    "## The trianing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZlZ7KlRhKiw"
   },
   "source": [
    "Generamos los datos usando la descripción de función con ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "dyRe4q-LSxF0"
   },
   "outputs": [],
   "source": [
    "# Create d datasets of n samples each\n",
    "# X \n",
    "d = 5 # number of datasets to create\n",
    "n = 100 # samples per dataset\n",
    "a, b = 0,10 # x domain range (a,b)\n",
    "f = np.vectorize(lambda x :  (0.45*x-2)**3 - 0.55*(0.2*x-3)**2-2.5*(0.5*x-3)+ 5) # True function that we would like to learn\n",
    "var = 0.5 # Noise to add to the true function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "TCl-ft8ffZBt"
   },
   "outputs": [],
   "source": [
    "# Seed for the random generator\n",
    "rng = default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "DttdqtnWa3DN"
   },
   "outputs": [],
   "source": [
    "def generate_datasets(d:int,n:int,f:np.vectorize,a:float,b:float,var:float):\n",
    "    \"\"\"\n",
    "    Creates datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    d: number of datasets\n",
    "    n: number of samples per dataset\n",
    "    f: function to use to generate the data\n",
    "    a: min of range x\n",
    "    b: max of range x\n",
    "    var: variance of the normal use to generate the noise\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: datasets with features\n",
    "    Y: datasets with targets\n",
    "\n",
    "    \"\"\"\n",
    "    X = rng.uniform(low=a,high=b,size=(d,n))\n",
    "    noise = rng.normal(loc=0,scale=np.sqrt(var),size=(d,n))\n",
    "    Y = f(X) + noise # True labels \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "A2Y_FdbAOjlU"
   },
   "outputs": [],
   "source": [
    "#x_datasets, y_datasets_w_noise = generate_datasets(d,n,f,a,b,var)\n",
    "X_trains, y_trains = generate_datasets(d,n,f,a,b,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "2wzmll0uBCqM"
   },
   "outputs": [],
   "source": [
    "d_test = 1\n",
    "n_test = 20\n",
    "X_tests, y_tests = generate_datasets(d_test,n_test,f=f,a=a,b=b,var=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV-PcAN3nvxw"
   },
   "source": [
    "## True $f$ (for future reference) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "VWuaJReGSxF7"
   },
   "outputs": [],
   "source": [
    "true_f_x = np.linspace(a,b,1000)\n",
    "true_f_y = f(true_f_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBhz3Gb0mzs4"
   },
   "source": [
    "## The test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "qx9XYnrUhQCF"
   },
   "outputs": [],
   "source": [
    "d_test = 1\n",
    "n_test = 20\n",
    "\n",
    "#x_test, y_test_w_noise = generate_datasets(d_test,n_test,f=f,a=a,b=b,var=var)\n",
    "X_tests, y_tests = generate_datasets(d_test,n_test,f=f,a=a,b=b,var=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-atomEV57kBi"
   },
   "source": [
    "## Save the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "YwkGZbbX8HCA"
   },
   "outputs": [],
   "source": [
    "def to_Xy_df(X,y):\n",
    "    \"\"\"\n",
    "    Converts a numpy dataset into a dataframe dataset.\n",
    "    Assumes X and y with shape (samples).\n",
    "    \"\"\"\n",
    "    Xy = np.concatenate([X.reshape(-1,1), y.reshape(-1,1)],axis=1)\n",
    "    Xy_df = pd.DataFrame(data = Xy.copy(), columns = [\"X\",\"y\"])\n",
    "    return Xy_df\n",
    "\n",
    "Xy_train_df = to_Xy_df(X_trains[0],y_trains[0]) \n",
    "Xy_test_df = to_Xy_df(X_tests[0],y_tests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "DMac88Qg8xDB"
   },
   "outputs": [],
   "source": [
    "Xy_train_df.to_csv(\"data/Xy_train.csv\",index=False)\n",
    "Xy_test_df.to_csv(\"data/Xy_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5ozCXTW5n40"
   },
   "source": [
    "## Ploting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Uzr03wkL5n47"
   },
   "outputs": [],
   "source": [
    "def f_plotly(i: int,x_datasets: np.array,y_datasets_w_noise: np.array,true_f_x: np.array,true_f_y: np.array):\n",
    "    \"\"\"\n",
    "    Plot the function and the data coming from it for specific dataset i in x_datasets (using plotly).\n",
    "    i: index to indicate which dataset to plot from x_datasets.\n",
    "    x_datasets: input features of the d datatsets.\n",
    "    y_datasets_w_noise: targets of the d datasets.\n",
    "    true_f_x: x coordinates of the points from the true function.\n",
    "    true_f_y: y cordinates of the points from the true function.\n",
    "    \"\"\"\n",
    "    fig = go.Figure(\n",
    "        layout=go.Layout(\n",
    "          title=go.layout.Title(text=f\"Samples and True Function. Dataset {i}\"),\n",
    "          xaxis_range = (0,10),\n",
    "          yaxis_range = (-4,20),\n",
    "          height=600,\n",
    "          width=600,\n",
    "          ))\n",
    "    fig.add_trace(go.Scatter(x=x_datasets[i,:],y=y_datasets_w_noise[i,:],mode='markers',name='samples'))\n",
    "    fig.add_trace(go.Scatter(x=true_f_x,y=true_f_y,mode='lines',name='true function'))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "76b3b139c4bf461bb5a8ce029b81f1e2",
      "7ea4e5d234394e57b77f65b49a3d2194",
      "833a3bf914c245089e3a7a7155daa244",
      "801d7c35c4ce4ff091f9c6404e387cd3",
      "263a2896525744928143418ee71b9aa7",
      "971061e35d36423fa3b31d5132b89d89",
      "2fac7a25c2704bcd9ac9ca5f2bb76be5"
     ]
    },
    "id": "4sHqocg55n48",
    "outputId": "161518af-3d2c-475f-b3ea-cc8336fca4b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c0e89f05bf44d49dd86295f8017478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=4), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(lambda i : f_plotly(i,X_trains,y_trains,true_f_x,true_f_y), i=widgets.IntSlider(min=0, max=d-1, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
